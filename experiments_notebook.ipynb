{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "from fastFM import als\n",
    "from scipy.sparse import csr_matrix\n",
    "import MeCab\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import csv\n",
    "from gensim import matutils\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import linear_model\n",
    "import codecs\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†æ•£è¡¨ç¾ã®èª­ã¿è¾¼ã¿\n",
    "- ã‚ã£ã¡ã‚ƒæ™‚é–“ã‹ã‹ã‚‹\n",
    "- ã“ã‚Œã¯ä¸€åº¦å®Ÿè¡Œã—ãŸå¾Œã¯ï¼Œãªã‚“ã©ã‚‚å®Ÿè¡Œã—ãªãã¦OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_w2v_hottolink = \"w2v_all_vector200_win5_sgns0.vec\"\n",
    "model_hottolink = KeyedVectors.load_word2vec_format(file_w2v_hottolink, binary=False)\n",
    "#model_hottolink = word2vec.Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é–¢æ•°ã®å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡ç« ã‚’mecabã§åˆ†ã‹ã¡ãŒãã—ã¦ã€åè©ãƒ»å‹•è©ãƒ»å½¢å®¹è©ã®å˜èªä¸€è¦§ã‚’è¿”ã™\n",
    "def wakati(text):\n",
    "    tagger = MeCab.Tagger()\n",
    "    tagger.parse('')\n",
    "    node = tagger.parseToNode(text)\n",
    "    word_list = []\n",
    "    while node:\n",
    "        features = node.feature.split(\",\")\n",
    "        pos = features[0]\n",
    "#        if pos in [\"åè©\", \"å‹•è©\", \"å½¢å®¹è©\", \"åŠ©å‹•è©\"]:\n",
    "        lemma = node.surface\n",
    "        word_list.append(lemma)\n",
    "            # æ¨™æº–å½¢ã«å¤‰æ›´\n",
    "        node = node.next\n",
    "\n",
    "    return word_list[1:-1]\n",
    "\n",
    "def parse():\n",
    "    lines = []\n",
    "    #for line in open('lastdata1_text.txt', 'r'):\n",
    "    for line in open('./sample_LDA_setdata/all_smptons_set1000_text.txt', 'r'):\n",
    "        arr = line.split(\"\\t\")\n",
    "        lines.append(arr)\n",
    "    return lines\n",
    "\n",
    "def vec2dense(vec, num_terms):\n",
    "    return list(matutils.corpus2dense([vec], num_terms=num_terms).T[0])\n",
    "#    return np.array(list(matutils.corpus2dense([vec], num_terms=num_terms).T[0]))\n",
    "def scores2mean(scores: List[float]) -> float:\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†æ•£è¡¨ç¾ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "50\n",
      "1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nf2 = open('./fit_data/text_word_count.csv', 'r')\\ndataReader = csv.reader(f2)\\nfor i , row in enumerate(dataReader):\\n    vectors[i] = np.append(vectors[i],float(row[0]))\\n\\nf = open('./fit_data/text_body_part.csv', 'r') \\ndataReader = csv.reader(f)\\nfor i , row in enumerate(dataReader):\\n    vectors[i] = np.append(vectors[i],float(row[0]))\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wakatis = []\n",
    "wakatis1 = []\n",
    "wakatis_bow = []\n",
    "wakatis_bow1 = []\n",
    "wakatis_bow = pd.read_csv(\"./sample_LDA_setdata/all_smptons_set1000_tsutsuzi.csv\",header = None).values.tolist()\n",
    "wakatis_bow1= pd.read_csv(\"./sample_LDA_setdata/all_smptons_set1000_LDA.csv\",header = None).values.tolist()\n",
    "print(len(wakatis_bow[0]))\n",
    "print(len(wakatis_bow1[0]))\n",
    "print(len(wakatis_bow))\n",
    "vectors = []\n",
    "vectors_bow = []\n",
    "lines = [t[0] for t in parse()]\n",
    "for line in lines:\n",
    "#    wakatis_bow.append(wakati(line))\n",
    "    words = wakati(line)    \n",
    "    embeddings = np.zeros(200)\n",
    "    count = 0\n",
    "    for line1 in words:\n",
    "        if line1 in model_hottolink.wv:\n",
    "            embeddings += model_hottolink[line1]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        embeddings /= count\n",
    "    vectors.append(deepcopy(embeddings))\n",
    "\n",
    "print(len(vectors))\n",
    "    \n",
    "\n",
    "#  ç´ æ€§è¿½åŠ   ##  \n",
    "\n",
    "\"\"\"\n",
    "f2 = open('./fit_data/text_word_count.csv', 'r')\n",
    "dataReader = csv.reader(f2)\n",
    "for i , row in enumerate(dataReader):\n",
    "    vectors[i] = np.append(vectors[i],float(row[0]))\n",
    "\n",
    "f = open('./fit_data/text_body_part.csv', 'r') \n",
    "dataReader = csv.reader(f)\n",
    "for i , row in enumerate(dataReader):\n",
    "    vectors[i] = np.append(vectors[i],float(row[0]))\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¿½åŠ ç´ æ€§\n",
    "- ä½“ã®éƒ¨ä½\n",
    "- ç—…å\n",
    "- å˜èªæ•°\n",
    "\n",
    "- ãã®ä»–è€ƒãˆã‚‰ã‚Œãã†ãªã‚‚ã®\n",
    "    - æ–‡å­—æ•°ï¼ˆæ–‡é•·ï¼‰\n",
    "    - BoW, PMI, word2vecã‚’å¤‰ãˆãªãŒã‚‰å®Ÿé¨“ã—ã¦ã¿ã‚‹\n",
    "    - ã¤ã¤ã˜ï¼Œãšã‚“ã ï¼Œã“ã®è¾ºã‚Šã¯ã¾ãŸä»Šåº¦è€ƒãˆã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(60 unique tokens: ['0951Q.1xx.03n01', '0751M.1xx.03n01', '0961Q.4xx.03n01', '3261M.1xx.46n01', '0961Q.2rx.03n01']...)\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "250\n",
      "1701\n",
      "310\n",
      "1701\n",
      "[ 0.          0.13988405  0.          0.          0.          0.\n",
      "  0.06679823  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.24481283  0.17313408  0.          0.\n",
      "  0.08548806  0.          0.          0.          0.          0.\n",
      "  0.3184396   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.38449832 -1.91864789 -1.36573228 -0.44868183\n",
      " -0.43701794  0.75139243  0.94758765 -1.05211136 -1.12704403 -1.25714665\n",
      " -0.43054632  0.57869546 -0.04318642  0.1317109   1.41145851  0.45100371\n",
      " -1.92065939 -0.20159236  0.40183058  0.33561963  2.26249808  0.0666333\n",
      "  1.21015073 -0.04312896  3.30113373 -2.84063125  2.59613114  0.10257151\n",
      " -0.36657735 -0.56741719 -1.85379276 -2.23011245  1.50815722 -0.26296148\n",
      "  1.24971269 -0.79783727 -2.86937387  1.09440591  2.00221154 -2.78085482\n",
      " -1.36160092  1.12385009 -1.31013797 -2.35822999 -1.54514988  0.89684055\n",
      "  0.16014604 -0.10001567 -0.74311611  2.04269793 -0.03773565  0.90084877\n",
      "  0.62035613 -1.2242102   2.20355499  0.37636277  0.67182417 -1.32053212\n",
      "  0.20115723  0.09001045  1.42502257 -0.02423449  0.47115319  0.69137062\n",
      "  0.81090396 -0.17843458  1.80331388  2.59512151 -5.05337467  5.23221329\n",
      " -0.16017505  0.19716287  2.10138443  1.99012987  0.18318693  0.28903627\n",
      "  2.20616615 -1.07520275 -1.09233353 -2.65525708  1.50418998  1.13568188\n",
      "  1.30031057 -0.65599711  1.4501414  -0.6387174  -0.07997283  2.76611932\n",
      "  1.3983714   0.96866247  1.80265773  0.58215795  2.48103952  2.54100973\n",
      " -2.03801064 -0.19395444  1.06833989 -1.35824582  1.15064023  0.97079068\n",
      "  0.32488364  1.80018816 -0.60978817  0.32591573 -1.48253497  0.49140225\n",
      "  0.70952933  1.61799253  0.06330314 -0.14330239  0.45271014  0.42393859\n",
      "  1.14919674 -0.50888105 -0.88480563 -1.99798231 -1.98756845 -0.14432245\n",
      "  0.25533357 -0.41283354  2.01493159  2.20398123 -1.48333906 -0.75813237\n",
      "  0.49125409 -1.99003042 -2.3053806   1.73937772 -0.42983623 -2.71908335\n",
      "  0.84830261 -1.42519616 -1.13844878 -0.35893792  2.13969866 -0.87895072\n",
      "  4.10450823  0.24054207 -0.91390593 -3.04834974 -2.44450893  0.2566461\n",
      "  1.09602479 -0.21838801  1.64400134 -1.16993006  0.07863849  0.13869831\n",
      " -0.9599676  -0.58428333 -0.08238841  3.21866582  0.91333213  2.27644215\n",
      "  1.46777664 -0.77900704  0.3380102  -0.42660233  1.40910615 -0.84065577\n",
      "  0.09841803  1.17598955 -0.91323557  2.84035791  1.14597709 -0.91458786\n",
      " -0.83462222  1.98612954 -1.98938551  2.3877723   0.39527825  1.76797198\n",
      "  0.949116    0.35616695  2.05219178 -1.13991977  1.2168034   1.27010938\n",
      "  0.4679808  -0.35038218  0.32119029  1.40533133  0.39716498 -1.38759289\n",
      "  1.71902645 -1.51389682 -0.6652458   2.7767414  -0.40463834 -0.13099055\n",
      "  1.71006465  1.25553081 -0.13150682 -0.58917013 -1.00934852 -0.54475113\n",
      " -0.93852693 -0.33817133  2.39927522 -2.26682795]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.28076512  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.06571499  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.75837481 -0.75790426 -0.11856069  0.6852673\n",
      "  0.12878575  0.18797917  0.37777386  0.45056213 -1.11714938 -0.64406145\n",
      " -1.42037721  0.29610806 -0.38938786  0.47688608  1.40177051  1.71802141\n",
      " -1.17355848 -0.71750313  0.52622521  0.06456059  2.16301216 -0.03433926\n",
      "  0.64434215  0.62496095  2.76397342 -2.81773569  0.00879506 -0.51569461\n",
      "  1.57380655 -0.76451286 -1.2862119  -1.82493255  1.85028176 -0.42016544\n",
      "  1.71010054 -0.55686349 -1.4515058   2.19412278  3.06598345 -1.72179792\n",
      " -2.02935039  1.09734168 -0.27624011 -1.75857536 -0.07252442  1.38188328\n",
      " -0.96836656  0.8750996  -0.19311636  1.26894179  0.38221619 -0.75952737\n",
      "  0.66366873 -2.02273081  2.5112431  -0.11503933  0.926401   -0.18004568\n",
      "  0.42205468 -1.09026656  1.66562305 -0.90169561  0.93616283  0.68906402\n",
      "  1.74328783  0.48573673  1.6980873   1.87423453 -3.42562952  4.82772499\n",
      " -0.88959037  0.49062103  2.45464198  1.40489657  0.42849372 -0.18123899\n",
      "  0.91591104 -2.1563139   0.12528693 -2.29575634  0.56624324  1.58563085\n",
      "  3.74962665 -0.85014392  1.54465495  0.82414045  0.78796686  0.45168513\n",
      "  1.74474493  0.57025023  2.48365305  0.42067402  1.28158132  2.63632638\n",
      " -2.37774058 -2.8312476   0.62940387 -0.42978024  0.7366463   0.89691644\n",
      " -1.113423    2.65711748 -0.83487665  0.64129826 -1.2857902   0.61908009\n",
      " -0.22467671  3.19395422  1.28027641 -1.14530699  0.38616933  0.68643507\n",
      "  0.92483204  0.44620827  0.0719118  -1.38289306 -1.10280062  1.16793812\n",
      " -0.65620429 -1.03230534  2.44528719  2.59293611 -1.20045901 -1.49259991\n",
      " -1.02956822 -1.60597116 -2.9520094   0.97490985 -0.19010623 -0.98057769\n",
      "  0.90108752 -0.7846908  -0.55428635 -0.7061403   3.72348566 -0.46442898\n",
      "  4.74510775 -0.61075169  0.87224032 -2.2857234  -2.41324808 -0.15238106\n",
      "  1.60649825  0.08408569  1.74978697 -0.24617482 -0.76487867  0.30684785\n",
      " -0.91550352  0.51880044  0.08042436  4.06950204  0.20583098  0.34820269\n",
      "  1.06530656 -0.80905019  1.38998916  0.03506348  1.53665194 -1.18913595\n",
      "  1.01819343  2.08602207  0.39963351  2.71747479  0.75640664 -1.96206752\n",
      " -1.69741412  1.21446267 -1.52403124  3.33677076 -0.34834044  1.83811599\n",
      "  2.13385246 -1.35241333  2.27921666 -0.88507007 -0.78177641  0.3795037\n",
      "  0.61971256  1.24897169 -0.60242009  0.93324332  0.99830626 -1.29119163\n",
      "  2.03054509 -0.37120962 -0.43012404  1.86261398  0.35522562  1.06676602\n",
      "  1.88909913 -0.45594802 -0.59492462  0.19161234 -0.5014968   0.04108744\n",
      " -2.52053754 -0.4543712   1.54846857 -1.52132405]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#  ç´ æ€§è¿½åŠ   ##\n",
    "f = open('./text_body_part1.csv', 'r') \n",
    "#f = open('./fit_data/text_body_part.csv', 'r') \n",
    "dataReader = csv.reader(f)\n",
    "for line , row in zip(vectors , dataReader):\n",
    "    np.append(line, float(row[0]))\n",
    "    # line.append(float(row[0]))\n",
    "    # â†‘word2vecã®å ´åˆã¯ï¼Œ`vectors`ãŒnumpyãƒ™ã‚¯ãƒˆãƒ«ã§ã‚ã‚‹ãŸã‚ï¼Œåˆ¥ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦ã„ã‚‹\n",
    "\n",
    "f1 = open('./text_sick1.csv', 'r')\n",
    "#f1 = open('./fit_data/text_sick.csv', 'r')\n",
    "dataReader1 = csv.reader(f1)\n",
    "for line , row in zip(vectors , dataReader1):\n",
    "    np.append(line, float(row[0]))\n",
    "    # line.append(float(row[0]))\n",
    "\n",
    "f2 = open('./fit_data/text_word_count.csv', 'r')\n",
    "dataReader2 = csv.reader(f2)\n",
    "for line, row in zip(vectors , dataReader2):\n",
    "    np.append(line, float(row[0]))\n",
    "    # line.append(float(row[0]))\n",
    "\n",
    "\n",
    "#  pmi  #\n",
    "ar_1 = vectors\n",
    "eps = 1e-8\n",
    "cm = np.array(ar_1)\n",
    "pmi = np.zeros_like(cm,dtype=np.float32)\n",
    "nsum = np.sum(cm)\n",
    "ssum = np.sum(cm,axis=0)\n",
    "for i in range(cm.shape[0]):\n",
    "    if i==200:\n",
    "         break\n",
    "    for j in range(cm.shape[1]):\n",
    "         pw = np.log2(cm[i,j] * nsum / (ssum[j] * ssum[i]) + eps)         \n",
    "         pmi[i,j] = max(0,pw)\n",
    "vectors = pmi\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "f = open('./tsutsuzi_label_sample2.csv', 'r') \n",
    "dataReader = csv.reader(f)\n",
    "for line , row in zip(wakatis_bow , dataReader):\n",
    "    if str(row[0]) != \"0.0\":\n",
    "        line.append(str(row[0]))\n",
    "  \n",
    "f1 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader1 = csv.reader(f1)\n",
    "for line1 , row1 in zip(wakatis_bow , dataReader1):\n",
    "    if str(row1[1]) != \"0.0\":\n",
    "        line1.append(str(row1[1]))\n",
    " \n",
    "f2 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader2 = csv.reader(f2)\n",
    "for line2 , row2 in zip(wakatis_bow , dataReader2):\n",
    "    if str(row2[2]) != \"0.0\":\n",
    "        line2.append(str(row2[2]))\n",
    "\n",
    "f3 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader3 = csv.reader(f3)\n",
    "for line3 , row3 in zip(wakatis_bow , dataReader3):\n",
    "    if str(row3[3]) != \"0.0\":\n",
    "        line3.append(str(row3[3]))\n",
    "\n",
    "f4 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader4 = csv.reader(f4)\n",
    "for line4 , row4 in zip(wakatis_bow , dataReader4):\n",
    "    if str(row4[4]) != \"0.0\":\n",
    "        line4.append(str(row4[4]))\n",
    " \n",
    "f5 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader5 = csv.reader(f5)\n",
    "for line5 , row5 in zip(wakatis_bow , dataReader5):\n",
    "    if str(row5[5]) != \"0.0\":\n",
    "        line5.append(str(row5[5]))\n",
    "\n",
    "f6 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader6 = csv.reader(f6)\n",
    "for line6 , row6 in zip(wakatis_bow , dataReader6):\n",
    "    if str(row6[6]) != \"0.0\":\n",
    "        line6.append(str(row6[6]))\n",
    "  \n",
    "f7 = open('./tsutsuzi_label_sample2.csv', 'r')\n",
    "dataReader7 = csv.reader(f7)\n",
    "for line7 , row7 in zip(wakatis_bow , dataReader7):\n",
    "    if str(row7[7]) != \"0.0\":\n",
    "        line7.append(str(row7[7]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(wakatis_bow)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.9)\n",
    "print(dictionary)\n",
    "vectors_bow = np.array([vec2dense(dictionary.doc2bow(wakatis_bow[i]), len(dictionary)) for i in range(len(wakatis_bow))], dtype='f8')\n",
    "print(vectors_bow[1])\n",
    "\n",
    "##  LDA  ##\n",
    "combined_vectors = []\n",
    "for bow, w2v, in zip(wakatis_bow1, vectors):\n",
    "     combined_vectors.append(np.hstack((bow,w2v)))\n",
    "print(len(combined_vectors[0]))\n",
    "print(len(combined_vectors))\n",
    "\n",
    "##  ã¤ã¤ã˜  ##\n",
    "np.insert(combined_vectors,[200],vectors_bow,axis=1)\n",
    "combined_vectors1 = []\n",
    "for bow, w2v in zip(vectors_bow, combined_vectors):\n",
    "    combined_vectors1.append(np.hstack((bow,w2v)))\n",
    "print(len(combined_vectors1[0]))\n",
    "print(len(combined_vectors1))\n",
    "\n",
    "print(combined_vectors[0])\n",
    "print(combined_vectors1[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.loadtxt('lastdata1_ans.csv',  delimiter=',', dtype='int')\n",
    "labels = np.loadtxt('./sample_LDA_setdata/all_smptons_set1000_ans.csv',  delimiter=',', dtype='int')\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "scores_dict_format: Dict[str, List[float]] = {\n",
    "    'precision': [], 'recall': [], 'f_measure': [], 'precision_weighted':[], 'recall_weighted':[], 'f1_weighted':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "1it [00:04,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       113\n",
      "           1       0.83      0.67      0.74        58\n",
      "\n",
      "    accuracy                           0.84       171\n",
      "   macro avg       0.84      0.80      0.81       171\n",
      "weighted avg       0.84      0.84      0.84       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "2it [00:09,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       116\n",
      "           1       0.75      0.67      0.71        54\n",
      "\n",
      "    accuracy                           0.82       170\n",
      "   macro avg       0.80      0.78      0.79       170\n",
      "weighted avg       0.82      0.82      0.82       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "3it [00:13,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       123\n",
      "           1       0.77      0.64      0.70        47\n",
      "\n",
      "    accuracy                           0.85       170\n",
      "   macro avg       0.82      0.78      0.80       170\n",
      "weighted avg       0.84      0.85      0.84       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "4it [00:18,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       117\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.87       170\n",
      "   macro avg       0.85      0.84      0.85       170\n",
      "weighted avg       0.87      0.87      0.87       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "5it [00:22,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       119\n",
      "           1       0.68      0.76      0.72        51\n",
      "\n",
      "    accuracy                           0.82       170\n",
      "   macro avg       0.79      0.81      0.80       170\n",
      "weighted avg       0.83      0.82      0.83       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "6it [00:27,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       112\n",
      "           1       0.76      0.67      0.72        58\n",
      "\n",
      "    accuracy                           0.82       170\n",
      "   macro avg       0.80      0.78      0.79       170\n",
      "weighted avg       0.81      0.82      0.81       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "7it [00:32,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       125\n",
      "           1       0.65      0.62      0.64        45\n",
      "\n",
      "    accuracy                           0.81       170\n",
      "   macro avg       0.76      0.75      0.75       170\n",
      "weighted avg       0.81      0.81      0.81       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "8it [00:36,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       111\n",
      "           1       0.77      0.75      0.76        59\n",
      "\n",
      "    accuracy                           0.84       170\n",
      "   macro avg       0.82      0.81      0.82       170\n",
      "weighted avg       0.83      0.84      0.83       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\r",
      "9it [00:41,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       111\n",
      "           1       0.74      0.71      0.72        59\n",
      "\n",
      "    accuracy                           0.81       170\n",
      "   macro avg       0.79      0.79      0.79       170\n",
      "weighted avg       0.81      0.81      0.81       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s15t283/svm_test_d/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "10it [00:45,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       116\n",
      "           1       0.72      0.80      0.75        54\n",
      "\n",
      "    accuracy                           0.84       170\n",
      "   macro avg       0.81      0.82      0.82       170\n",
      "weighted avg       0.84      0.84      0.84       170\n",
      "\n",
      "\n",
      "class: -1(macro_mean) \n",
      "precision: 0.8685719217204758 \n",
      "precision_weighted: 0.8685719217204758 recall 0.8889907109048816 recall_weighted: 0.8685719217204758 f_measure 0.8782198431313836 f1_weighted: 0.8685719217204758\n",
      "\n",
      "class:  1(macro_mean) \n",
      "precision: 0.7478457367758407 \n",
      "precision_weighted: 0.7478457367758407 recall 0.7064228550389894 recall_weighted: 0.7478457367758407 f_measure 0.7246202227327534 f1_weighted: 0.7478457367758407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results: Dict[int, Dict[str, List[float]]\n",
    "              ] = {-1: deepcopy(scores_dict_format), 1: deepcopy(scores_dict_format)}\n",
    "accuracies = []\n",
    "for train_index, test_index in tqdm(kf.split(combined_vectors, labels)):\n",
    "    train_data = [combined_vectors[idx] for idx in train_index]\n",
    "    #train_data = np.array([combined_vectors[idx] for idx in train_index])\n",
    "    train_labels = [labels[idx] for idx in train_index]\n",
    "    #train_labels = np.array([labels[idx] for idx in train_index])\n",
    "    test_data = [combined_vectors[idx] for idx in test_index]\n",
    "    test_labels = [labels[idx] for idx in test_index]\n",
    "                   \n",
    "    #model = als.FMClassification(n_iter=1000, init_stdev=0.1, rank=2, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "    #model.fit(csr_matrix(train_data), train_labels)\n",
    "    \n",
    "    ##  ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚¹å›å¸°  ##\n",
    "    #model = linear_model.LogisticRegression(random_state=0)\n",
    "    #model.fit(train_data, train_labels)\n",
    "    \n",
    "    ##  SVM  ##\n",
    "    #model = SVC(kernel='rbf', random_state=0, C=1000)#, gamma=\"scale\")\n",
    "    #model.fit(train_data, train_labels)\n",
    "    \n",
    "    ## Multi layer perceptron ##\n",
    "    model = MLPClassifier(solver='sgd', batch_size=128)\n",
    "    model.fit(train_data, train_labels)\n",
    "    \n",
    "    pred_labels = model.predict(test_data)\n",
    "    accuracies.append(accuracy_score(test_labels, pred_labels))\n",
    "    p, r, f, _ = precision_recall_fscore_support(test_labels, pred_labels)\n",
    "    results[-1]['precision'].append(p[0])\n",
    "    results[-1]['recall'].append(r[0])\n",
    "    results[-1]['f_measure'].append(f[0])\n",
    "    results[1]['precision'].append(p[1])\n",
    "    results[1]['recall'].append(r[1])\n",
    "    results[1]['f_measure'].append(f[1])\n",
    "    \n",
    "    results[-1]['precision_weighted'].append(p[0])\n",
    "    results[1]['precision_weighted'].append(p[1])\n",
    "    results[-1]['recall_weighted'].append(p[0])\n",
    "    results[1]['recall_weighted'].append(p[1])\n",
    "    results[-1]['f1_weighted'].append(p[0])\n",
    "    results[1]['f1_weighted'].append(p[1])\n",
    "    \n",
    "    print(classification_report(test_labels,model.predict(test_data)))\n",
    "\n",
    "#    for c , p , t in zip(test_labels , pred_labels , lines):\n",
    "#        if c != p:\n",
    "#            print(c,p,t)\n",
    "\n",
    "    #df = list(d.items())\n",
    "    #print (d.keys())\n",
    "    \n",
    "    # print('class: -1', results[-1])\n",
    "print('\\nclass: -1(macro_mean)',\n",
    "      '\\nprecision:', scores2mean(results[-1]['precision']),\n",
    "      '\\nprecision_weighted:', scores2mean(results[-1]['precision_weighted']),\n",
    "      'recall', scores2mean(results[-1]['recall']),\n",
    "      'recall_weighted:', scores2mean(results[-1]['recall_weighted']),  \n",
    "      'f_measure', scores2mean(results[-1]['f_measure']),\n",
    "      'f1_weighted:', scores2mean(results[-1]['f1_weighted']))\n",
    "# print('class:  1', results[1])\n",
    "print('\\nclass:  1(macro_mean)',\n",
    "      '\\nprecision:', scores2mean(results[1]['precision']),\n",
    "      '\\nprecision_weighted:', scores2mean(results[1]['precision_weighted']),\n",
    "      'recall', scores2mean(results[1]['recall']),\n",
    "      'recall_weighted:', scores2mean(results[1]['recall_weighted']),\n",
    "      'f_measure', scores2mean(results[1]['f_measure']),\n",
    "      'f1_weighted:', scores2mean(results[1]['f1_weighted']))\n",
    "\n",
    "#print(((scores2mean(results[-1]['precision_weighted']))+(scores2mean(results[1]['precision_weighted']))) / 2.0)\n",
    "#print(((scores2mean(results[-1]['recall_weighted']))+(scores2mean(results[1]['recall_weighted']))) / 2.0)\n",
    "#print(((scores2mean(results[-1]['f1_weighted']))+(scores2mean(results[1]['f1_weighted']))) / 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm \n",
    "#### word2vec\n",
    "Fclass: -1(macro_mean) \n",
    "precision: 0.7559140299372962 recall 0.7144076721450139 f_measure 0.7323472242955001\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7122171063423284 recall 0.7582533810218722 f_measure 0.7324821540127525\n",
    "\n",
    "#### word2vec+ç—…å\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7558769307820346 recall 0.7144076721450139 f_measure 0.7323006004212901\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7123384347274013 recall 0.7586004614628685 f_measure 0.7326731272440975\n",
    "\n",
    "#### word2vec+éƒ¨ä½\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7510065186004868 recall 0.7155715164706229 f_measure 0.7305426192252337\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7113255195828777 recall 0.7505846411662427 f_measure 0.728373567598106\n",
    "\n",
    "#### word2vec+æ–‡é•· \n",
    "class: -1(macro_mean) \n",
    "precision: 0.7549770930003593 recall 0.7144076721450139 f_measure 0.7318203752580128\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7119840061092282 recall 0.7570905903241977 f_measure 0.7317339870218801\n",
    "\n",
    "#### word2vec+3ç´ æ€§\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7497172677967044 recall 0.7143950458823876 f_measure 0.7291640620550615\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7103821947808755 recall 0.7498081261016211 f_measure 0.7273705901392942\n",
    "\n",
    "### MLP\n",
    "#### word2vec\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7190290388941041 recall 0.7316442283000363 f_measure 0.7233889547336847\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7057989254463405 recall 0.6968113618494095 f_measure 0.6993334167722509\n",
    "\n",
    "#### word2vec+ç—…å\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7265466291598826 recall 0.7153768202716453 f_measure 0.7187895540245088\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7006216137788077 recall 0.7133205601221 f_measure 0.7046645183156733\n",
    "\n",
    "#### word2vec+éƒ¨ä½\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7261581534651302 recall 0.7130075463545308 f_measure 0.7171599673538495\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.6993122187295194 recall 0.7165268780924017 f_measure 0.7051272209948094\n",
    "\n",
    "#### word2vec+æ–‡é•·\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7390313823692203 recall 0.7199383524765134 f_measure 0.7271926104241068\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7080127913895308 recall 0.7282764160763009 f_measure 0.715977786588644\n",
    "\n",
    "#### word2vec+3ç´ æ€§\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7232418720450512 recall 0.7210102333547977 f_measure 0.7199297460710744\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.703361281312904 recall 0.7072590589736242 f_measure 0.7031391663512795\n",
    "\n",
    "### ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚¹å›å¸°\n",
    "#### word2vec\n",
    "\n",
    "\n",
    "#### word2vec+ç—…å\n",
    "\n",
    "\n",
    "#### word2vec+éƒ¨ä½\n",
    "\n",
    "\n",
    "#### word2vec+æ–‡é•·\n",
    "\n",
    "\n",
    "#### word2vec+3ç´ æ€§\n",
    "class: -1(macro_mean) \n",
    "precision: 0.7226595176162555 recall 0.6885464518934363 f_measure 0.7031535607992214\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.6843165868658938 recall 0.7213928781468446 f_measure 0.7000704210006579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-9-42fc1ebba3b5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-42fc1ebba3b5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1 -1 ãã‚Œã¯ã©ã†ã‹ãªåº¶æ°‘ã¯å‰åŠã¯ç„¡é›£ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã¤ã¤ç—ºã‚Œã‚’åˆ‡ã‚‰ã—ãŸã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã®èª˜å°ãŒå§‹ã¾ã£ãŸã‚ãŸã‚Šã§å…¨åŠ›ã§ç­”ãˆã‚’è€ƒãˆã¦ãªã‚“ã¨ãªãè¿‘ã„è¨€è‘‰ã°ã‹ã‚Šç™ºã—ã¦è¡Œãã¨ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ãŒä¹—ã‚Šå‡ºã™ã‹ã‚‰ãã“ã‚’ç‹™ã£ã¦ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã‚’èª˜å°ã™ã‚‹ã®ãŒé ­ã„ã„ã€‚\u001b[0m\n\u001b[0m                                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "1 -1 ãã‚Œã¯ã©ã†ã‹ãªåº¶æ°‘ã¯å‰åŠã¯ç„¡é›£ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã¤ã¤ç—ºã‚Œã‚’åˆ‡ã‚‰ã—ãŸã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã®èª˜å°ãŒå§‹ã¾ã£ãŸã‚ãŸã‚Šã§å…¨åŠ›ã§ç­”ãˆã‚’è€ƒãˆã¦ãªã‚“ã¨ãªãè¿‘ã„è¨€è‘‰ã°ã‹ã‚Šç™ºã—ã¦è¡Œãã¨ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ãŒä¹—ã‚Šå‡ºã™ã‹ã‚‰ãã“ã‚’ç‹™ã£ã¦ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã‚’èª˜å°ã™ã‚‹ã®ãŒé ­ã„ã„ã€‚\n",
    "\n",
    "1 -1 ã‚‚ãã‚‚ãç—‡å€™ç¾¤ã¨ã¯å®šæœŸçš„ã«ã‚°ã‚¦ã‚§ãƒ³ã‚’æ‘‚å–ã—ãªã„ã¨éœ‡ãˆã‚„å‹•æ‚¸ã€ã‚ã¾ã„ã€åãæ°—ã€æ‰‹è¶³ã®ç—ºã‚Œãªã©ã®ç—‡çŠ¶ãŒå‡ºã‚‹ç—…æ°—ã€‚\n",
    "\n",
    "-1 1 ç™ºç†±ã§ä¼‘ã‚“ã å…ƒæ°—ãªå¹¼å…ãŒã„ã¾ã™(ã—ã‚“ã©ã„\n",
    "\n",
    "-1 1 ç—›ã¿ã¯æ•°æ—¥ã§ãŠã•ã¾ã‚Šã¾ã—ãŸãŒã€ä¸‹é¡ã®ç—ºã‚Œã¯åŠå¹´çµŒã£ãŸç¾åœ¨ã§ã‚‚å°‘ã—æ®‹ã£ã¦ã—ã¾ã„ã¾ã—ãŸã€‚\n",
    "\n",
    "-1 1 ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¶ã¨ã‹ã«ãªã£ã¦æœ‰ä¼‘æ¶ˆåŒ–ã—ãŸã„ã¨ã‹æ€ã£ã¦ãŸã‘ã©é–“é•ã£ã¦ãŸã—ã‚“ã©ã„ã‚ã€‚\n",
    "\n",
    "1 -1 ï¼‰ã€ã£ã¦ãªã£ãŸã‚“ã ã‘ã©å¸°ã£ã¦é¡è¦‹ãŸã‚‰ç›®ãŒã™ã’ãƒ¼å……è¡€ã—ã¦ã‚‹ã—ç›®ã®ä¸‹ã«æ¼«ç”»ã¿ãŸã„ãªæ¿ƒã•ã®ã‚¯ãƒã‚‚ã§ãã¦ãŸã®ã§ã³ã£ãã‚‰ã“ã„ãŸï¼ˆã§ã‚‚å…ƒæ°—ï¼‰\n",
    "\n",
    "1 -1 ã‚ã¾ã„ãŒâ€¦\n",
    "\n",
    "1 -1 æ€ãˆã°ã€å…ˆé€±ã®æœ¨æ›œæ—¥ã‹ã‚‰æ¬¡ç”·ç™ºç†±ã€‚\n",
    "\n",
    "1 -1 ã£ã¦ã„ã†å£°ã¨ãƒ‹ãƒ¤ãƒ‹ãƒ¤ã¨å‹•æ‚¸ãŒæ­¢ã¾ã‚‰ãªã„ã‚“ã§ã™ã‘ã©ã©ã†ã—ãŸã‚‰ã„ã„ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "1 -1 è‡ªåˆ†ã‚­ãƒ¢ã™ãã¦åãæ°—ã™ã‚‹ã‚wãªã‚“ã§ã“ã‚“ãªæ€§æ ¼ãªã‚“ã ã‚ã­\n",
    "\n",
    "1 -1 ã‚«ãƒ³ã‚¿ãã‚“ã«å½±éŸ¿ã•ã‚Œã¦å§‹ã‚ãŸãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ğŸƒâ™‚ï¸ğŸƒâ™€ï¸é€±4ã€œ5å›èµ°ã‚‹ã®ã‚’2é€±é–“ç¶šã‘ãŸã‚‰ã€æ¯åˆ‡ã‚Œã‹ã‚‰ã®å›å¾©é€Ÿåº¦ãŒé€Ÿããªã£ãŸï¼\n",
    "\n",
    "-1 1 å¤ã®ã‚ã¾ã„feat.\n",
    "\n",
    "-1 1 é ­ç—›è–¬ã‚­ãƒ¡ã¦ãŸã›ã„ã§çŒ®è¡€ã§ããªã‹ã£ãŸâ€¦â€¦â€¦å…ƒæ°—ã§ã™ï¼\n",
    "\n",
    "-1 1 æ˜¨æ—¥ã‹ã‚‰å°‘ã—é ­ç—›ã—ã¦ã„ã¦ã€è–¬é£²ã‚“ã§ã‚‚ã‚ã‚“ã¾åŠ¹ã‹ã­ãƒ¼ã—ã€æ›´ã«ä»Šæœèµ·ããŸã‚‰å‹•ããŸã³ã«ç—›ã¿ãŒãšããšããã‚‹ã‚‚ã‚“ã ã‹ã‚‰ãªã‚“ãï¼Ÿ\n",
    "\n",
    "1 -1 é›¨ã‹ã‚‰ã®æ€¥ãªæ™´ã‚Œã®æ—¥ã¯å‹•æ‚¸ãŒã—ã¦ãƒ›ãƒ³ãƒˆã—ã‚“ã©ã„â€¦å¿ƒã‚’ç„¡ã«ã—ã¦é›»è»Šã«ä¹—ã‚‹å¤ãŒã‚‚ã†ã™ãã‚„ã£ã¦ãã‚‹ï¼\n",
    "\n",
    "1 -1 æ™´ã‚Œã¦ã‚‹ã®ã«é–¢ç¯€ç—›ãŒã²ã©ã„.\n",
    "\n",
    "1 -1 æ‰‹ã®ç”²ã«ã¯é£Ÿå™¨ç”¨æ´—å‰¤ã«è² ã‘ã¦ç™ºç–¹ãŒå‡ºæ¥ã¡ã‚‡ã£ãŸã‘ã©ã€å…¥é™¢ã—ã¦ã‹ã‚‰ã©ã£ã¡ã‚‚ç¶ºéº—ã«æ²»ã£ãŸã€‚\n",
    "\n",
    "-1 1 å‹•æ‚¸ã¨ã„ã†ã‹ã€æ€¥ã«å¿ƒè‡“ãŒãƒã‚¯ãƒã‚¯ã™ã‚‹ã®ã¯ä¸æ•´è„ˆï¼Ÿ\n",
    "\n",
    "-1 1 ã†ã‚ï½ç«‹ã£ãŸã‚‰ã€å°‘ã—ã‚ã¾ã„ã£ã½ããªã£ãŸâ€¦ãã—ã¦ã€é£›èšŠç—‡ã‚‚ã€ã¡ã‚‰ã£ã¨ã—ãŸ(-\"\"-;)æœ€è¿‘ã€ã‚²ãƒ¼ãƒ ã®ã—éãã‹ãªâ€¦çœ¼ç²¾ç–²åŠ´ã ãªã\n",
    "\n",
    "-1 1 ã“ã‚Œã£ã¦ã„ã†äº‹ãªã‚“ã ã¨ã—ã¦é–¢ç¯€ç—›ãŒéãã¦ã„ã‚‹æ°—æŒã¡ãŒã™ã‚‹ã‚“ã ã‘ã© \n",
    "\n",
    "-1 1 é ­ç—›ã„ã„çœ ã„ã—ã ã‚‹ã„ã—è¶³ç­‹è‚‰ç—›ã£ã½ã„ã—\n",
    "\n",
    "1 -1 ãã®å¾Œã«çªç™ºæ€§ç™ºç–¹ãŒå‡ºã‚‹ã‹ã‚‚ã­ã¨ã‚‚è¨€ã‚ã‚ŒãŸã€‚\n",
    "\n",
    "-1 1 ã£ã¨æ€ã£ã¦ãŸã‘ã©ä»Šæœã™ã£ã‹ã‚Šç†±ã¯ä¸‹ãŒã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "-1 1 ç™ºç–¹ã¯æ°—ã«ãªã‚‹ã‘ã©ã€ç™ºç†±ã‚‚ãªãã€ãƒŸãƒ«ã‚¯ã‚‚ã—ã£ã‹ã‚Šé£²ã‚ã¦ã‚‹ãªã‚‰æ§˜å­è¦‹ã§ã„ã„ã‚“ã˜ã‚ƒãªã„ã‹ã€ã¨ã€å®‰å¿ƒã—ã¦ã„ã„ã‚“ã ã‹ã€ã˜ã‚ƒã‚ã“ã®ç™ºç–¹ã¯ãªã‚“ãªã‚“ã ã¨å¿ƒé…ã¯æ¶ˆãˆãšã€‚\n",
    "\n",
    "1 -1 7æ—¥ã‹ã‚‰5é€£å‹¤ã®äºˆå®šã ã£ãŸã‘ã©5æ—¥é–“ç™ºç†±ã—å€’ã—ã¦ã¦åœŸæ›œæ—¥ã¯39åº¦ã€æ—¥æ›œæ—¥ã¯åãæ°—é…·ãã¦ä¼‘æ—¥è¨ºç™‚æ‰€ã§èƒƒè…¸ç‚ã¨è¨€ã‚ã‚Œ1æ—¥åˆ†ã®è–¬ã‚’è²°ã„ã€ã©ãƒ¼ã«ã‹10æ—¥ã«ä»•äº‹å¾©å¸°ã—ãŸã®ã«ãã®å¤œã«é£Ÿã¹ãŸä½•ã‹ã—ã‚‰ã§å…¨èº«è•éº»ç–¹ã§ã¦ã€æ¬¡ã®æ—¥ã®æœã«èµ¤ã„ç™ºç–¹ã«å¤‰ã‚ã‚Šã€ä¼‘æ†©æ™‚é–“ã«è¡Œã£ãŸç—…é™¢ã§\n",
    "\n",
    "1 -1 åãæ°—ã‚„ã°\n",
    "\n",
    "1 -1 )çš†ã‚‚ã“ã‚“ãªå‹•æ‚¸ã™ã‚‹ã‚“ã ï¼Ÿ\n",
    "\n",
    "-1 1 ã¾ãä¸€é€±é–“ã»ã©ã“ã®ã¾ã¾ä½¿ã£ã¦ã¿ã¾ã™ã‹ãƒ¼æ™‚ã€…è§¦ã£ã¦ã©ã‚Œãã‚‰ã„ç†±ããªã‚‹ã®ã‹è¦‹ã¨ã“ã‚‚ã¨ã‚‚ã¨çµæ§‹ç™ºç†±ã™ã‚‹ã‘ã©\n",
    "\n",
    "-1 1 æµçŸ³ã«39åº¦è¿‘ãã¾ã§è¡Œã£ãŸç™ºç†±ã¯ä¸€æ™©ã˜ã‚ƒæ²»ã‚‰ã‚“ã‚ãªã€‚\n",
    "\n",
    "-1 1 æ˜¨æ—¥ç´¹ä»‹çŠ¶ã‚‚ã‚‰ã£ã¦ç—…é™¢è¡Œã£ãŸã‘ã©æ‰‹è¶³å£ç—…ã˜ã‚ƒãªã‹ã£ãŸç¬‘2åº¦ç›®ã®çªç™ºæ€§ç™ºç–¹ï¼\n",
    "\n",
    "1 -1 â—å¨˜ã®ç—‡çŠ¶è¶³ã®è£ã‹ã‚‰ã€ãµã¨ã‚‚ã‚‚ä¸‹ã«ã‹ã‘ã¦èµ¤ã„ç™ºç–¹ãŒãŸãã•ã‚“å‡ºã‚‹é…ã‚Œã¦ã€æ‰‹æŒ‡ã€è…•ã«ã‹ã‘ã¦ç™ºç–¹ç¿Œæ—¥æ‰‹è¶³ã®æŒ‡å…ˆä»˜è¿‘ã«æ°´ç–±ãŒã§ã‚‹\n",
    "\n",
    "-1 1 é¢¨é‚ªã‚­ãƒ¡ãŸã‚“ã§ã™ã‘ã©ç™ºç†±ã¨å’³ã«åŠ¹ãç·åˆé¢¨é‚ªè–¬è²·ã£ãŸç›´å¾Œæœ¬å½“ã«ã‚„ã°ã„ã®ã¯é¼»ã®æ–¹ã ã£ã¦äº‹ã«æ°—ã¥ã„ã¦ã—ã¾ã£ãŸã®ã§é¼»ã«åŠ¹ãã‚„ã¤è²·ãˆã°ã‚ˆã‹ã£ãŸã‚ã€œã€œã€œã£ã¦æ€ã„ã¾ã—ãŸ \n",
    "\n",
    "1 -1 ãã†è¨€ãˆã°æ˜¨æ—¥ã¯åµç„¼ãã¨ãƒ“ãƒ¼ãƒ«ã—ã‹èƒƒã«å…¥ã‚Œã¦ãªã„ãªã€æœèµ·ããŸæ™‚åãæ°—ã‚„ã°ãã¦ã³ã£ãã‚Šã—ãŸ\n",
    "\n",
    "1 -1 ã†ãˆãƒ¼é ­ç—›\n",
    "\n",
    "-1 1 ã¾ã˜ã§é–¢ç¯€ç—›ã‚„ã°ã„ä»®ç—…ã§ä»•äº‹ä¼‘ã‚“ã§å¹³æ—¥ä¼‘ã¿ãŸã„\n",
    "\n",
    "-1 1 æ˜¨æ—¥ã¾ã§40åº¦è¿‘ãã‚ã£ãŸç†±ã‚‚ä»Šæ—¥ã¯å¹³ç†±ã§å®‰å¿ƒï¼\n",
    "\n",
    "1 -1 çŸ¥ã‚‰ãªã„äººãŒã¶ã¤ã‹ã£ã¦ãã‚‹ã ã‘ã§åãæ°—ã™ã‚‹\n",
    "\n",
    "-1 1 è‡ªåˆ†ã®ç”»åŠ›ãŒä½ã™ãã¦åœ°ã®åº•ã‚’é€™ã£ã¦ã‚‹ãƒ¬ãƒ™ãƒ«ãªã›ã„ã§å‹•æ‚¸ã—ã¦ããŸ\n",
    "\n",
    "-1 1 ç™ºç†± \n",
    "\n",
    "-1 1 ãŸã ã—é ­ã®å¾Œã‚ã«ã‚´ãƒ ã‚’å›ã™ã‚¿ã‚¤ãƒ—ã ã¨é«ªã‚’å·»ãè¾¼ã‚€ã®ãŒæ°—ã«ãªã‚‹ã—ã€é•·ã•ã‚’ã†ã¾ãèª¿æ•´ã—ãªã„ã¨ç· ã‚ä»˜ã‘æ„Ÿã§è»½ã„é ­ç—›ã£ã½ããªã‚‹ã€‚\n",
    "\n",
    "-1 1 æ˜”ã‹ã‚‰ãã†ã ã‘ã©ã€è‡ªåˆ†ã®äºˆå®šã‚’æ€¥ã«èª°ã‹ã«ä¹±ã•ã‚Œã‚‹ã®ãŒå®Ÿéš›ã«åãæ°—ã‚’å‚¬ã™ãã‚‰ã„ã«å«Œã„ã£ã½ã„ãªãã©ã†ã«ã‹ãªã‚‰ã‚“ã‹ãªã‚³ãƒ¬\n",
    "\n",
    "1 -1 æœèµ·ããŸã‚‰é›ªå±±ã§ã‚´ãƒ¼ã‚°ãƒ«ã—ãªã‹ã£ãŸæ™‚ã¿ãŸã„ã«ç›®ãŒç–²ã‚Œã¦å……è¡€ã—ã¦ã‚‹ã‚“ã§ã™ã‘ã©æ˜¨æ—¥ã®ç¾½ç”Ÿçµå¼¦ã•ã‚“ãŒã‚ã¾ã‚Šã«ã‚‚çœ©ã—ã™ããŸã‹ã‚‰ã‹ãªâ€¦ğŸ‘¼ğŸ»ğŸŒ¤\n",
    "\n",
    "-1 1 è…°ã¯3å›ç›®ã ã‘ã©ã€å…¥é™¢ä¸­ã¨ã‹å…¨ãç—›ããªãã¦ã€ä»Šå›ç—ºã‚Œã¾ãã£ã¦ã‚‹ã®ä½•ã“ã‚Œâ€¦\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class: -1(macro_mean) \n",
    "precision: 0.8597758500776866 \n",
    "precision_weighted: 0.8597758500776866 recall 0.8883631038211288 recall_weighted: 0.8597758500776866 f_measure 0.8734145898578933 f1_weighted: 0.8597758500776866\n",
    "\n",
    "class:  1(macro_mean) \n",
    "precision: 0.7339829286358177 \n",
    "precision_weighted: 0.7339829286358177 recall 0.6740374147239484 recall_weighted: 0.7339829286358177 f_measure 0.6994706189692754 f1_weighted: 0.7339829286358177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
